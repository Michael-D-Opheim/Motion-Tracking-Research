{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6af4438d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Main Tracking Software\n",
    "\n",
    "Michael Opheim, 1/16/2022\n",
    "Adapted from Sergio Canu's motion tracking software\n",
    "\n",
    "This program tracks and quantifies object movement within videos files.\n",
    "\n",
    "Instructions:\n",
    "1. Download 'tracker' software from https://pysource.com/2021/01/28/object-tracking-with-opencv-and-python/\n",
    "2. In cv2.VideoCapture, type in the title of your mp4 file.\n",
    "3. Find the dimensions of your video by unquoting the 'print(height, width)' command.\n",
    "4. Use these dimensions to create your specific region of interest, or 'roi' variable (the exact region you would like the program to monitor for movement).\n",
    "5. Run the program to track and collect the relative (x,y) coordinates of your desired moving object(s).\n",
    "\n",
    "Tips:\n",
    "1. Press the 'q' key to end the program at any time.\n",
    "2. The number assignments corresponding to the variables 'varThreshold' and 'area' can be adjusted to reduce the \"noise\" your video.\n",
    "3. Y-coordinates are, by default, backwards. To fix this, change the 'directions.append' command to 'detections.append([x, height - y, w, h])'.\n",
    "    - Note: this will remove the tracking boxes from your video, so be sure to utilize this change after you have made sure that your object tracking is working as intended.\n",
    "4. Issues and errors can be reported to michaeldopheim@gmail.com, where tech support will be provided.\n",
    "\n",
    "'''\n",
    "\n",
    "import cv2\n",
    "from tracker import *\n",
    "\n",
    "#creates tracker object\n",
    "tracker = EuclideanDistTracker()\n",
    "\n",
    "#reads frames from the video\n",
    "capture = cv2.VideoCapture(\"Video_Title.mp4\")\n",
    "\n",
    "#extracts moving objects\n",
    "object_detector = cv2.createBackgroundSubtractorMOG2(history = 100, varThreshold = 30) #threshold can be changed to remove false positives\n",
    "\n",
    "#loops through video frames\n",
    "while True:\n",
    "    ret, frame = capture.read()\n",
    "    height, width, _ = frame.shape #finds dimensions of video\n",
    "    '''print(height, width)''' #use this to find height and width of the video\n",
    "    \n",
    "    if ret:\n",
    "        roi = frame[605: 1080, 20: 1500] #extracts region of interest [height, width]\n",
    "    \n",
    "    #object detection\n",
    "        mask = object_detector.apply(roi) #applies object detection to the region of interest (\"roi\" could also be replaced with the variable \"frame\", which scans the entire video)\n",
    "        _, mask = cv2.threshold(mask, 254, 255, cv2.THRESH_BINARY) #removes the gray from the mask to stop detecting object shadows\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) #finds contours in the mask\n",
    "        detections = [] #where (x, y, w, h) coordinates are collected\n",
    "        for cnt in contours:\n",
    "            area = cv2.contourArea(cnt) #calculates object areas and removes small elements\n",
    "            if area > 500: #if area is greater than 500 pixels...\n",
    "                '''cv2.drawContours(roi, [cnt], -1, (0, 255, 0), 2)''' #highlights contours as green (\"roi\" could also be replaced with the variable \"frame\")\n",
    "                x, y, w, h = cv2.boundingRect(cnt)\n",
    "                detections.append([x, y, w, h]) #adds coordinates to detections variable\n",
    "        '''print(detections)''' #simply prints the detection coordinates\n",
    "    \n",
    "    #object tracking\n",
    "        boxes_ids = tracker.update(detections) #gives a novel ID to newly detected objects\n",
    "        '''print(boxes_ids)''' #simply prints coordinates with their object IDs\n",
    "        for box_id in boxes_ids:\n",
    "            x, y, w, h, id = box_id\n",
    "            cv2.putText(roi, str(id), (x, y - 15), cv2.FONT_HERSHEY_PLAIN, 2, (255, 0, 0), 2) #places box ID on box in video frame\n",
    "            cv2.rectangle(roi, (x, y), (x + w, y + h), (0, 255, 0), 3) #highlights contours with a green rectangle\n",
    "    \n",
    "        '''cv2.imshow(\"roi\", roi)''' #shows the frames in the region of interest - use this to ensure that the region's dimensions are accurate\n",
    "        cv2.imshow(\"Frame\", frame) #shows the video's frames in real time\n",
    "        '''cv2.imshow(\"Mask\", mask)''' #shows the video in its mask format\n",
    "        key = cv2.waitKey(30) #wait time in milliseconds before each frame is presented\n",
    "        if key == ord('q'): #press the 'q' key to close the video window\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "for i in range (1,5):\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce638c79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
